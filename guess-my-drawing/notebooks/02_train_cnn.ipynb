{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# üß† Entra√Ænement CNN - Guess My Drawing\n",
        "\n",
        "## üéØ Objectifs\n",
        "- Cr√©er et entra√Æner le CNN pour reconna√Ætre 5 classes de dessins\n",
        "- Architecture optimis√©e pour 28x28 pixels\n",
        "- Target: 85%+ accuracy sur test set\n",
        "- Monitoring avec TensorBoard\n",
        "\n",
        "## üìä Donn√©es\n",
        "- **Cat** : 123,202 dessins  \n",
        "- **Dog** : 152,159 dessins\n",
        "- **House** : 135,420 dessins\n",
        "- **Car** : 182,764 dessins\n",
        "- **Tree** : 144,721 dessins\n",
        "\n",
        "**Plan :** √âquilibrer √† 123,000 images par classe (615,000 total)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from pathlib import Path\n",
        "from datetime import datetime\n",
        "import time\n",
        "\n",
        "# Configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"üî• Device: {device}\")\n",
        "\n",
        "# Param√®tres d'entra√Ænement\n",
        "BATCH_SIZE = 64\n",
        "LEARNING_RATE = 0.001\n",
        "EPOCHS = 10\n",
        "NUM_CLASSES = 5\n",
        "\n",
        "# Classes et emojis\n",
        "CLASSES = ['cat', 'dog', 'house', 'car', 'tree']\n",
        "CLASS_EMOJIS = ['üê±', 'üê∂', 'üè†', 'üöó', 'üå≥']\n",
        "\n",
        "print(f\"‚öôÔ∏è Configuration:\")\n",
        "print(f\"   Batch size: {BATCH_SIZE}\")\n",
        "print(f\"   Learning rate: {LEARNING_RATE}\")\n",
        "print(f\"   Epochs: {EPOCHS}\")\n",
        "print(f\"   Classes: {CLASSES}\")\n",
        "print(\"‚úÖ Imports termin√©s!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Architecture CNN\n",
        "class DrawingCNN(nn.Module):\n",
        "    \"\"\"CNN optimis√© pour dessins Quick Draw 28x28\"\"\"\n",
        "    \n",
        "    def __init__(self, num_classes=5):\n",
        "        super(DrawingCNN, self).__init__()\n",
        "        \n",
        "        # Bloc convolutionnel 1: 28x28 -> 14x14\n",
        "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(32)\n",
        "        self.pool1 = nn.MaxPool2d(2, 2)\n",
        "        \n",
        "        # Bloc convolutionnel 2: 14x14 -> 7x7\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(64)\n",
        "        self.pool2 = nn.MaxPool2d(2, 2)\n",
        "        \n",
        "        # Bloc convolutionnel 3: 7x7 -> 7x7\n",
        "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
        "        self.bn3 = nn.BatchNorm2d(128)\n",
        "        \n",
        "        # Couches fully connected\n",
        "        self.fc1 = nn.Linear(128 * 7 * 7, 512)\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "        self.fc2 = nn.Linear(512, num_classes)\n",
        "        \n",
        "        # Initialisation des poids\n",
        "        self._init_weights()\n",
        "    \n",
        "    def _init_weights(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_out')\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "            elif isinstance(m, nn.Linear):\n",
        "                nn.init.normal_(m.weight, 0, 0.01)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        # Bloc 1\n",
        "        x = self.pool1(F.relu(self.bn1(self.conv1(x))))\n",
        "        \n",
        "        # Bloc 2  \n",
        "        x = self.pool2(F.relu(self.bn2(self.conv2(x))))\n",
        "        \n",
        "        # Bloc 3\n",
        "        x = F.relu(self.bn3(self.conv3(x)))\n",
        "        \n",
        "        # Flatten\n",
        "        x = x.view(x.size(0), -1)\n",
        "        \n",
        "        # FC\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "        \n",
        "        return x\n",
        "    \n",
        "    def predict_proba(self, x):\n",
        "        \"\"\"Probabilit√©s avec softmax\"\"\"\n",
        "        with torch.no_grad():\n",
        "            logits = self.forward(x)\n",
        "            return F.softmax(logits, dim=1)\n",
        "\n",
        "# Test du mod√®le\n",
        "model = DrawingCNN(num_classes=NUM_CLASSES).to(device)\n",
        "params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(\"üß† ARCHITECTURE CNN\")\n",
        "print(\"=\" * 30)\n",
        "print(f\"üî¢ Param√®tres: {params:,}\")\n",
        "print(f\"üíæ Taille estim√©e: {params * 4 / 1024 / 1024:.1f} MB\")\n",
        "\n",
        "# Test forward pass\n",
        "test_input = torch.randn(1, 1, 28, 28).to(device)\n",
        "with torch.no_grad():\n",
        "    output = model(test_input)\n",
        "    print(f\"üìä Test: {test_input.shape} -> {output.shape}\")\n",
        "    print(\"‚úÖ Architecture valid√©e!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Dataset personnalis√©\n",
        "class QuickDrawDataset(Dataset):\n",
        "    \"\"\"Dataset pour les donn√©es Quick Draw\"\"\"\n",
        "    \n",
        "    def __init__(self, data_dir, classes, max_samples_per_class=50000, train=True):\n",
        "        self.data_dir = Path(data_dir)\n",
        "        self.classes = classes\n",
        "        self.class_to_idx = {cls: idx for idx, cls in enumerate(classes)}\n",
        "        self.train = train\n",
        "        \n",
        "        # Charger les donn√©es\n",
        "        print(\"üìä Chargement des donn√©es...\")\n",
        "        self.images = []\n",
        "        self.labels = []\n",
        "        \n",
        "        for class_idx, class_name in enumerate(classes):\n",
        "            print(f\"   {CLASS_EMOJIS[class_idx]} Chargement {class_name}...\")\n",
        "            \n",
        "            # Charger le fichier .npy\n",
        "            filepath = self.data_dir / f\"{class_name}.npy\"\n",
        "            data = np.load(filepath)\n",
        "            \n",
        "            # Limiter le nombre d'√©chantillons\n",
        "            if len(data) > max_samples_per_class:\n",
        "                # M√©langer et prendre les premiers max_samples_per_class\n",
        "                indices = np.random.permutation(len(data))[:max_samples_per_class]\n",
        "                data = data[indices]\n",
        "            \n",
        "            # Ajouter aux listes\n",
        "            self.images.extend(data)\n",
        "            self.labels.extend([class_idx] * len(data))\n",
        "            \n",
        "            print(f\"     -> {len(data):,} images ajout√©es\")\n",
        "        \n",
        "        # Convertir en numpy arrays\n",
        "        self.images = np.array(self.images)\n",
        "        self.labels = np.array(self.labels)\n",
        "        \n",
        "        print(f\"‚úÖ Dataset cr√©√©: {len(self.images):,} images total\")\n",
        "        print(f\"   Shape: {self.images.shape}\")\n",
        "        print(f\"   Distribution: {np.bincount(self.labels)}\")\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        # R√©cup√©rer l'image et le label\n",
        "        image = self.images[idx].reshape(28, 28).astype(np.float32)\n",
        "        label = self.labels[idx]\n",
        "        \n",
        "        # Normalisation: Quick Draw a noir=255, blanc=0\n",
        "        # On inverse pour avoir noir=0, blanc=1, puis on normalise [-1, 1]\n",
        "        image = 255 - image  # Inverser\n",
        "        image = image / 255.0  # [0, 1]\n",
        "        image = (image - 0.5) / 0.5  # [-1, 1]\n",
        "        \n",
        "        # Ajouter dimension channel\n",
        "        image = image[np.newaxis, ...]  # (1, 28, 28)\n",
        "        \n",
        "        return torch.FloatTensor(image), torch.LongTensor([label])[0]\n",
        "\n",
        "# Cr√©er le dataset\n",
        "project_root = Path('.').parent\n",
        "data_dir = project_root / \"data\"\n",
        "\n",
        "# Dataset complet\n",
        "print(\"üîÑ Cr√©ation du dataset...\")\n",
        "full_dataset = QuickDrawDataset(\n",
        "    data_dir=data_dir,\n",
        "    classes=CLASSES,\n",
        "    max_samples_per_class=80000,  # √âquilibr√©, mais pas trop pour la vitesse\n",
        "    train=True\n",
        ")\n",
        "\n",
        "# Split train/validation/test\n",
        "total_size = len(full_dataset)\n",
        "train_size = int(0.7 * total_size)\n",
        "val_size = int(0.15 * total_size)\n",
        "test_size = total_size - train_size - val_size\n",
        "\n",
        "train_dataset, val_dataset, test_dataset = random_split(\n",
        "    full_dataset, [train_size, val_size, test_size]\n",
        ")\n",
        "\n",
        "print(f\"üìä Splits:\")\n",
        "print(f\"   Train: {len(train_dataset):,} images\")\n",
        "print(f\"   Validation: {len(val_dataset):,} images\") \n",
        "print(f\"   Test: {len(test_dataset):,} images\")\n",
        "\n",
        "# DataLoaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)\n",
        "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
        "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
        "\n",
        "print(f\"üì¶ DataLoaders cr√©√©s:\")\n",
        "print(f\"   Train batches: {len(train_loader)}\")\n",
        "print(f\"   Val batches: {len(val_loader)}\")\n",
        "print(f\"   Test batches: {len(test_loader)}\")\n",
        "print(\"‚úÖ Donn√©es pr√™tes!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Configuration TensorBoard et optimiseur\n",
        "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
        "writer = SummaryWriter(f'../runs/drawing_cnn_{timestamp}')\n",
        "\n",
        "# R√©initialiser le mod√®le pour un entra√Ænement propre\n",
        "model = DrawingCNN(num_classes=NUM_CLASSES).to(device)\n",
        "\n",
        "# Optimiseur et scheduler\n",
        "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=1e-4)\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.7)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "print(f\"‚öôÔ∏è Configuration entra√Ænement:\")\n",
        "print(f\"   TensorBoard: runs/drawing_cnn_{timestamp}\")\n",
        "print(f\"   Optimiseur: Adam (lr={LEARNING_RATE})\")\n",
        "print(f\"   Scheduler: StepLR (step=3, gamma=0.7)\")\n",
        "print(f\"   Loss: CrossEntropyLoss\")\n",
        "\n",
        "# Fonctions d'entra√Ænement et validation\n",
        "def train_epoch(model, loader, optimizer, criterion, epoch, writer):\n",
        "    \"\"\"Entra√Æne le mod√®le pour une √©poque\"\"\"\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    \n",
        "    for batch_idx, (data, target) in enumerate(loader):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = criterion(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        # Statistiques\n",
        "        running_loss += loss.item()\n",
        "        pred = output.argmax(dim=1)\n",
        "        correct += pred.eq(target).sum().item()\n",
        "        total += target.size(0)\n",
        "        \n",
        "        # Log TensorBoard toutes les 100 batches\n",
        "        if batch_idx % 100 == 0:\n",
        "            step = epoch * len(loader) + batch_idx\n",
        "            writer.add_scalar('Train/Loss_Batch', loss.item(), step)\n",
        "            writer.add_scalar('Train/Accuracy_Batch', 100. * correct / total, step)\n",
        "            \n",
        "            print(f'   Batch {batch_idx:3d}/{len(loader)} | '\n",
        "                  f'Loss: {loss.item():.4f} | '\n",
        "                  f'Acc: {100. * correct / total:.2f}%')\n",
        "    \n",
        "    epoch_loss = running_loss / len(loader)\n",
        "    epoch_acc = 100. * correct / total\n",
        "    \n",
        "    # Log √©poque\n",
        "    writer.add_scalar('Train/Loss_Epoch', epoch_loss, epoch)\n",
        "    writer.add_scalar('Train/Accuracy_Epoch', epoch_acc, epoch)\n",
        "    \n",
        "    return epoch_loss, epoch_acc\n",
        "\n",
        "def validate_epoch(model, loader, criterion, epoch, writer):\n",
        "    \"\"\"Valide le mod√®le\"\"\"\n",
        "    model.eval()\n",
        "    val_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for data, target in loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            val_loss += criterion(output, target).item()\n",
        "            pred = output.argmax(dim=1)\n",
        "            correct += pred.eq(target).sum().item()\n",
        "            total += target.size(0)\n",
        "    \n",
        "    val_loss /= len(loader)\n",
        "    val_acc = 100. * correct / total\n",
        "    \n",
        "    # Log validation\n",
        "    writer.add_scalar('Val/Loss', val_loss, epoch)\n",
        "    writer.add_scalar('Val/Accuracy', val_acc, epoch)\n",
        "    \n",
        "    print(f'   Validation | Loss: {val_loss:.4f} | Acc: {val_acc:.2f}%')\n",
        "    \n",
        "    return val_loss, val_acc\n",
        "\n",
        "print(\"‚úÖ Fonctions d'entra√Ænement pr√™tes!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# üöÄ ENTRA√éNEMENT PRINCIPAL\n",
        "print(\"üî• D√âBUT DE L'ENTRA√éNEMENT\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Ajouter graphe du mod√®le √† TensorBoard\n",
        "sample_input = torch.randn(1, 1, 28, 28).to(device)\n",
        "writer.add_graph(model, sample_input)\n",
        "\n",
        "# Historique des m√©triques\n",
        "train_losses, train_accs = [], []\n",
        "val_losses, val_accs = [], []\n",
        "best_val_acc = 0.0\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    epoch_start = time.time()\n",
        "    \n",
        "    print(f\"\\nüìÖ √âPOQUE {epoch+1}/{EPOCHS}\")\n",
        "    print(\"-\" * 30)\n",
        "    \n",
        "    # Entra√Ænement\n",
        "    print(\"üèãÔ∏è Entra√Ænement...\")\n",
        "    train_loss, train_acc = train_epoch(model, train_loader, optimizer, criterion, epoch, writer)\n",
        "    train_losses.append(train_loss)\n",
        "    train_accs.append(train_acc)\n",
        "    \n",
        "    # Validation\n",
        "    print(\"üîç Validation...\")\n",
        "    val_loss, val_acc = validate_epoch(model, val_loader, criterion, epoch, writer)\n",
        "    val_losses.append(val_loss)\n",
        "    val_accs.append(val_acc)\n",
        "    \n",
        "    # Learning rate scheduler\n",
        "    scheduler.step()\n",
        "    current_lr = optimizer.param_groups[0]['lr']\n",
        "    writer.add_scalar('Train/Learning_Rate', current_lr, epoch)\n",
        "    \n",
        "    # Sauvegarder le meilleur mod√®le\n",
        "    if val_acc > best_val_acc:\n",
        "        best_val_acc = val_acc\n",
        "        torch.save({\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'val_acc': val_acc,\n",
        "            'train_acc': train_acc,\n",
        "        }, f'../models/best_model_{timestamp}.pth')\n",
        "        print(f\"   üíæ Nouveau meilleur mod√®le sauv√©! (Val Acc: {val_acc:.2f}%)\")\n",
        "    \n",
        "    epoch_time = time.time() - epoch_start\n",
        "    print(f\"   ‚è±Ô∏è Temps √©poque: {epoch_time:.1f}s | LR: {current_lr:.6f}\")\n",
        "    print(f\"   üìä Train: {train_acc:.2f}% | Val: {val_acc:.2f}% | Best: {best_val_acc:.2f}%\")\n",
        "\n",
        "total_time = time.time() - start_time\n",
        "\n",
        "print(f\"\\nüéâ ENTRA√éNEMENT TERMIN√â!\")\n",
        "print(\"=\" * 50)\n",
        "print(f\"‚è±Ô∏è Temps total: {total_time/60:.1f} minutes\")\n",
        "print(f\"üèÜ Meilleure accuracy validation: {best_val_acc:.2f}%\")\n",
        "print(f\"üìà Accuracy finale train: {train_accs[-1]:.2f}%\")\n",
        "print(f\"üìâ Loss finale train: {train_losses[-1]:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# üìä √âVALUATION FINALE ET VISUALISATIONS\n",
        "\n",
        "# Visualisation des courbes d'apprentissage\n",
        "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 10))\n",
        "\n",
        "epochs_range = range(1, EPOCHS + 1)\n",
        "\n",
        "# Loss\n",
        "ax1.plot(epochs_range, train_losses, 'b-', label='Train', linewidth=2)\n",
        "ax1.plot(epochs_range, val_losses, 'r-', label='Validation', linewidth=2)\n",
        "ax1.set_title('Loss par √©poque', fontsize=14, fontweight='bold')\n",
        "ax1.set_xlabel('√âpoque')\n",
        "ax1.set_ylabel('Loss')\n",
        "ax1.legend()\n",
        "ax1.grid(True, alpha=0.3)\n",
        "\n",
        "# Accuracy\n",
        "ax2.plot(epochs_range, train_accs, 'b-', label='Train', linewidth=2)\n",
        "ax2.plot(epochs_range, val_accs, 'r-', label='Validation', linewidth=2)\n",
        "ax2.set_title('Accuracy par √©poque', fontsize=14, fontweight='bold')\n",
        "ax2.set_xlabel('√âpoque')\n",
        "ax2.set_ylabel('Accuracy (%)')\n",
        "ax2.legend()\n",
        "ax2.grid(True, alpha=0.3)\n",
        "\n",
        "# Distribution des classes (subplot 3)\n",
        "test_predictions = []\n",
        "test_true_labels = []\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    for data, target in test_loader:\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        output = model(data)\n",
        "        pred = output.argmax(dim=1)\n",
        "        test_predictions.extend(pred.cpu().numpy())\n",
        "        test_true_labels.extend(target.cpu().numpy())\n",
        "\n",
        "# Matrice de confusion simplifi√©e\n",
        "from collections import Counter\n",
        "pred_counter = Counter(test_predictions)\n",
        "true_counter = Counter(test_true_labels)\n",
        "\n",
        "class_names_with_emoji = [f\"{CLASS_EMOJIS[i]} {cls}\" for i, cls in enumerate(CLASSES)]\n",
        "\n",
        "ax3.bar(range(len(CLASSES)), [pred_counter[i] for i in range(len(CLASSES))], \n",
        "        alpha=0.7, label='Pr√©dictions')\n",
        "ax3.bar(range(len(CLASSES)), [true_counter[i] for i in range(len(CLASSES))], \n",
        "        alpha=0.7, label='Vraies classes')\n",
        "ax3.set_title('Distribution Test Set', fontsize=14, fontweight='bold')\n",
        "ax3.set_xlabel('Classes')\n",
        "ax3.set_ylabel('Nombre d\\'√©chantillons')\n",
        "ax3.set_xticks(range(len(CLASSES)))\n",
        "ax3.set_xticklabels(class_names_with_emoji, rotation=45)\n",
        "ax3.legend()\n",
        "ax3.grid(True, alpha=0.3)\n",
        "\n",
        "# Accuracy par classe\n",
        "correct_per_class = [0] * len(CLASSES)\n",
        "total_per_class = [0] * len(CLASSES)\n",
        "\n",
        "for true_label, pred_label in zip(test_true_labels, test_predictions):\n",
        "    total_per_class[true_label] += 1\n",
        "    if true_label == pred_label:\n",
        "        correct_per_class[true_label] += 1\n",
        "\n",
        "class_accuracies = [100 * correct_per_class[i] / max(total_per_class[i], 1) \n",
        "                   for i in range(len(CLASSES))]\n",
        "\n",
        "bars = ax4.bar(range(len(CLASSES)), class_accuracies, \n",
        "               color=['#FF6B6B', '#4ECDC4', '#45B7D1', '#96CEB4', '#FFEAA7'])\n",
        "ax4.set_title('Accuracy par classe', fontsize=14, fontweight='bold')\n",
        "ax4.set_xlabel('Classes')\n",
        "ax4.set_ylabel('Accuracy (%)')\n",
        "ax4.set_xticks(range(len(CLASSES)))\n",
        "ax4.set_xticklabels(class_names_with_emoji, rotation=45)\n",
        "ax4.grid(True, alpha=0.3)\n",
        "\n",
        "# Ajouter les valeurs sur les barres\n",
        "for bar, acc in zip(bars, class_accuracies):\n",
        "    height = bar.get_height()\n",
        "    ax4.text(bar.get_x() + bar.get_width()/2., height + 1,\n",
        "             f'{acc:.1f}%', ha='center', va='bottom', fontweight='bold')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Sauvegarder dans TensorBoard\n",
        "writer.add_figure('Results/Training_Summary', fig)\n",
        "\n",
        "# Calcul accuracy test finale\n",
        "test_correct = sum([1 for true, pred in zip(test_true_labels, test_predictions) if true == pred])\n",
        "test_total = len(test_true_labels)\n",
        "test_accuracy = 100. * test_correct / test_total\n",
        "\n",
        "print(\"üéØ R√âSULTATS FINAUX\")\n",
        "print(\"=\" * 40)\n",
        "print(f\"üìä Test Accuracy: {test_accuracy:.2f}%\")\n",
        "print(f\"üèÜ Meilleure Val Accuracy: {best_val_acc:.2f}%\")\n",
        "print(f\"‚è±Ô∏è Temps d'entra√Ænement: {total_time/60:.1f} min\")\n",
        "print(f\"üíæ Mod√®le sauv√©: models/best_model_{timestamp}.pth\")\n",
        "\n",
        "# Accuracy par classe d√©taill√©e\n",
        "print(\"\\nüìà ACCURACY PAR CLASSE:\")\n",
        "for i, (cls, acc) in enumerate(zip(CLASSES, class_accuracies)):\n",
        "    print(f\"   {CLASS_EMOJIS[i]} {cls.capitalize():8s}: {acc:5.1f}%\")\n",
        "\n",
        "# √âvaluation de l'objectif\n",
        "if test_accuracy >= 85.0:\n",
        "    print(f\"\\nüéâ OBJECTIF ATTEINT! Test accuracy {test_accuracy:.1f}% >= 85%\")\n",
        "    status = \"SUCCESS ‚úÖ\"\n",
        "else:\n",
        "    print(f\"\\n‚ö†Ô∏è Objectif manqu√©. Test accuracy {test_accuracy:.1f}% < 85%\")\n",
        "    status = \"NEEDS_IMPROVEMENT ‚ö†Ô∏è\"\n",
        "\n",
        "print(f\"\\nüèÅ STATUS: {status}\")\n",
        "\n",
        "# Fermer TensorBoard\n",
        "writer.close()\n",
        "print(f\"\\nüåê TensorBoard: tensorboard --logdir=../runs\")\n",
        "print(f\"üìÅ Run: drawing_cnn_{timestamp}\")\n",
        "print(\"‚úÖ Session termin√©e!\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
