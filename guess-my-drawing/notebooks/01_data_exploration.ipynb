{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# ðŸŽ¨ Exploration des donnÃ©es Quick Draw\n",
        "\n",
        "## ðŸ“‹ Objectifs\n",
        "- Explorer le format des donnÃ©es Quick Draw\n",
        "- Visualiser des exemples de dessins\n",
        "- Comprendre la distribution des classes\n",
        "- PrÃ©parer le preprocessing pour l'entraÃ®nement\n",
        "\n",
        "## ðŸ“Š Nos 5 classes MVP\n",
        "1. ðŸ± **Cat** : 123,202 dessins\n",
        "2. ðŸ¶ **Dog** : 152,159 dessins  \n",
        "3. ðŸ  **House** : 135,420 dessins\n",
        "4. ðŸš— **Car** : 182,764 dessins\n",
        "5. ðŸŒ³ **Tree** : 144,721 dessins\n",
        "\n",
        "**Total : 738,266 dessins !** ðŸ”¥\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "# Configuration matplotlib\n",
        "plt.style.use('default')\n",
        "plt.rcParams['figure.figsize'] = (12, 8)\n",
        "\n",
        "# Chemins\n",
        "project_root = Path('.').parent\n",
        "data_dir = project_root / \"data\"\n",
        "\n",
        "# Classes\n",
        "CLASSES = ['cat', 'dog', 'house', 'car', 'tree']\n",
        "CLASS_EMOJIS = ['ðŸ±', 'ðŸ¶', 'ðŸ ', 'ðŸš—', 'ðŸŒ³']\n",
        "\n",
        "print(\"ðŸ“¦ Imports terminÃ©s!\")\n",
        "print(f\"ðŸ“ Dossier data: {data_dir}\")\n",
        "print(f\"ðŸŽ¯ Classes: {CLASSES}\")\n",
        "\n",
        "# VÃ©rification des fichiers\n",
        "for class_name in CLASSES:\n",
        "    filepath = data_dir / f\"{class_name}.npy\"\n",
        "    if filepath.exists():\n",
        "        print(f\"âœ… {class_name}.npy trouvÃ©\")\n",
        "    else:\n",
        "        print(f\"âŒ {class_name}.npy manquant\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Chargement et analyse des donnÃ©es\n",
        "data_stats = {}\n",
        "\n",
        "print(\"ðŸ“Š ANALYSE DES DONNÃ‰ES\")\n",
        "print(\"=\" * 40)\n",
        "\n",
        "for i, class_name in enumerate(CLASSES):\n",
        "    filepath = data_dir / f\"{class_name}.npy\"\n",
        "    \n",
        "    # Charger les donnÃ©es\n",
        "    data = np.load(filepath)\n",
        "    \n",
        "    # Statistiques\n",
        "    data_stats[class_name] = {\n",
        "        'emoji': CLASS_EMOJIS[i],\n",
        "        'count': len(data),\n",
        "        'shape': data.shape,\n",
        "        'size_mb': filepath.stat().st_size / 1024 / 1024,\n",
        "        'min': data.min(),\n",
        "        'max': data.max(),\n",
        "        'mean': data.mean()\n",
        "    }\n",
        "    \n",
        "    stats = data_stats[class_name]\n",
        "    print(f\"{stats['emoji']} {class_name.upper()}\")\n",
        "    print(f\"   ðŸ“Š Images: {stats['count']:,}\")\n",
        "    print(f\"   ðŸ“ Shape: {stats['shape']}\")\n",
        "    print(f\"   ðŸ’¾ Taille: {stats['size_mb']:.1f} MB\")\n",
        "    print(f\"   ðŸŽ¨ Pixels: min={stats['min']}, max={stats['max']}, mean={stats['mean']:.1f}\")\n",
        "    print()\n",
        "\n",
        "# RÃ©sumÃ© global\n",
        "total_images = sum(stats['count'] for stats in data_stats.values())\n",
        "total_size = sum(stats['size_mb'] for stats in data_stats.values())\n",
        "\n",
        "print(\"ðŸŒŸ RÃ‰SUMÃ‰ GLOBAL\")\n",
        "print(\"-\" * 20)\n",
        "print(f\"ðŸ“Š Total images: {total_images:,}\")\n",
        "print(f\"ðŸ’¾ Total taille: {total_size:.1f} MB\")\n",
        "print(f\"ðŸ“ Format images: 28x28 (784 pixels)\")\n",
        "print(f\"ðŸŽ¨ Valeurs pixels: 0-255 (noir=255, blanc=0)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualisation d'exemples de dessins\n",
        "def show_examples(num_examples=5):\n",
        "    \"\"\"Affiche des exemples de dessins pour chaque classe\"\"\"\n",
        "    \n",
        "    fig, axes = plt.subplots(len(CLASSES), num_examples, figsize=(15, 12))\n",
        "    fig.suptitle('ðŸŽ¨ Exemples de dessins Quick Draw', fontsize=16, fontweight='bold')\n",
        "    \n",
        "    for class_idx, class_name in enumerate(CLASSES):\n",
        "        # Charger les donnÃ©es de cette classe\n",
        "        filepath = data_dir / f\"{class_name}.npy\"\n",
        "        data = np.load(filepath)\n",
        "        \n",
        "        # Prendre des exemples alÃ©atoires\n",
        "        random_indices = np.random.choice(len(data), num_examples, replace=False)\n",
        "        \n",
        "        for example_idx in range(num_examples):\n",
        "            ax = axes[class_idx, example_idx]\n",
        "            \n",
        "            # Obtenir l'image et la redimensionner en 28x28\n",
        "            img = data[random_indices[example_idx]].reshape(28, 28)\n",
        "            \n",
        "            # Afficher (inverser les couleurs pour un fond blanc)\n",
        "            ax.imshow(255 - img, cmap='gray')\n",
        "            ax.axis('off')\n",
        "            \n",
        "            # Titre pour la premiÃ¨re colonne seulement\n",
        "            if example_idx == 0:\n",
        "                emoji = CLASS_EMOJIS[class_idx]\n",
        "                ax.set_title(f'{emoji} {class_name.title()}', \n",
        "                           fontsize=12, fontweight='bold', pad=10)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "print(\"ðŸ–¼ï¸ VISUALISATION DES EXEMPLES\")\n",
        "print(\"=\" * 30)\n",
        "show_examples(6)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Distribution des classes et prÃ©paration\n",
        "print(\"ðŸ“Š DISTRIBUTION DES CLASSES\")\n",
        "print(\"=\" * 30)\n",
        "\n",
        "# Graphique de distribution\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
        "\n",
        "# Graphique en barres\n",
        "class_names = list(data_stats.keys())\n",
        "class_counts = [data_stats[name]['count'] for name in class_names]\n",
        "class_labels = [f\"{CLASS_EMOJIS[i]} {name.title()}\" for i, name in enumerate(class_names)]\n",
        "\n",
        "bars = ax1.bar(class_labels, class_counts, color=['#FF6B6B', '#4ECDC4', '#45B7D1', '#96CEB4', '#FFEAA7'])\n",
        "ax1.set_title('Nombre d\\'images par classe', fontsize=14, fontweight='bold')\n",
        "ax1.set_ylabel('Nombre d\\'images')\n",
        "ax1.tick_params(axis='x', rotation=45)\n",
        "\n",
        "# Ajouter les valeurs sur les barres\n",
        "for bar, count in zip(bars, class_counts):\n",
        "    height = bar.get_height()\n",
        "    ax1.text(bar.get_x() + bar.get_width()/2., height + 1000,\n",
        "             f'{count:,}', ha='center', va='bottom', fontweight='bold')\n",
        "\n",
        "# Graphique en camembert\n",
        "ax2.pie(class_counts, labels=class_labels, autopct='%1.1f%%', startangle=90,\n",
        "        colors=['#FF6B6B', '#4ECDC4', '#45B7D1', '#96CEB4', '#FFEAA7'])\n",
        "ax2.set_title('RÃ©partition des classes', fontsize=14, fontweight='bold')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Recommandations pour l'Ã©quilibrage\n",
        "print(\"ðŸ’¡ RECOMMANDATIONS POUR L'ENTRAÃŽNEMENT\")\n",
        "print(\"-\" * 40)\n",
        "\n",
        "min_count = min(class_counts)\n",
        "max_count = max(class_counts)\n",
        "imbalance_ratio = max_count / min_count\n",
        "\n",
        "print(f\"ðŸ“Š Classe la plus reprÃ©sentÃ©e: {max_count:,} images\")\n",
        "print(f\"ðŸ“‰ Classe la moins reprÃ©sentÃ©e: {min_count:,} images\") \n",
        "print(f\"âš–ï¸ Ratio de dÃ©sÃ©quilibre: {imbalance_ratio:.1f}x\")\n",
        "\n",
        "if imbalance_ratio > 1.5:\n",
        "    print(\"âš ï¸ DÃ©sÃ©quilibre dÃ©tectÃ© ! Options:\")\n",
        "    print(\"   1. Utiliser le mÃªme nombre d'images pour toutes les classes\")\n",
        "    print(\"   2. Appliquer des poids aux classes lors de l'entraÃ®nement\")\n",
        "    print(\"   3. Augmentation de donnÃ©es pour les classes sous-reprÃ©sentÃ©es\")\n",
        "    \n",
        "    # Suggestion d'Ã©quilibrage\n",
        "    balanced_count = min_count\n",
        "    print(f\"\\nâœ… Suggestion: Utiliser {balanced_count:,} images par classe\")\n",
        "    print(\"   -> Dataset Ã©quilibrÃ© de\", f\"{balanced_count * len(CLASSES):,} images total\")\n",
        "else:\n",
        "    print(\"âœ… Les classes sont bien Ã©quilibrÃ©es !\")\n",
        "\n",
        "print(\"\\nðŸš€ PROCHAINES Ã‰TAPES\")\n",
        "print(\"-\" * 20)\n",
        "print(\"1. Preprocessing: normalisation et redimensionnement\")\n",
        "print(\"2. Split train/validation/test\") \n",
        "print(\"3. Architecture CNN adaptÃ©e Ã  28x28\")\n",
        "print(\"4. EntraÃ®nement avec monitoring TensorBoard\")\n",
        "print(\"5. Ã‰valuation et optimisation\")\n",
        "\n",
        "print(\"\\nâœ¨ DonnÃ©es prÃªtes pour l'entraÃ®nement ! âœ¨\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
