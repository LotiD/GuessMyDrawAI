{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# 🎨 Exploration des données Quick Draw\n",
        "\n",
        "## 📋 Objectifs\n",
        "- Explorer le format des données Quick Draw\n",
        "- Visualiser des exemples de dessins\n",
        "- Comprendre la distribution des classes\n",
        "- Préparer le preprocessing pour l'entraînement\n",
        "\n",
        "## 📊 Nos 5 classes MVP\n",
        "1. 🐱 **Cat** : 123,202 dessins\n",
        "2. 🐶 **Dog** : 152,159 dessins  \n",
        "3. 🏠 **House** : 135,420 dessins\n",
        "4. 🚗 **Car** : 182,764 dessins\n",
        "5. 🌳 **Tree** : 144,721 dessins\n",
        "\n",
        "**Total : 738,266 dessins !** 🔥\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "# Configuration matplotlib\n",
        "plt.style.use('default')\n",
        "plt.rcParams['figure.figsize'] = (12, 8)\n",
        "\n",
        "# Chemins\n",
        "project_root = Path('.').parent\n",
        "data_dir = project_root / \"data\"\n",
        "\n",
        "# Classes\n",
        "CLASSES = ['cat', 'dog', 'house', 'car', 'tree']\n",
        "CLASS_EMOJIS = ['🐱', '🐶', '🏠', '🚗', '🌳']\n",
        "\n",
        "print(\"📦 Imports terminés!\")\n",
        "print(f\"📁 Dossier data: {data_dir}\")\n",
        "print(f\"🎯 Classes: {CLASSES}\")\n",
        "\n",
        "# Vérification des fichiers\n",
        "for class_name in CLASSES:\n",
        "    filepath = data_dir / f\"{class_name}.npy\"\n",
        "    if filepath.exists():\n",
        "        print(f\"✅ {class_name}.npy trouvé\")\n",
        "    else:\n",
        "        print(f\"❌ {class_name}.npy manquant\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Chargement et analyse des données\n",
        "data_stats = {}\n",
        "\n",
        "print(\"📊 ANALYSE DES DONNÉES\")\n",
        "print(\"=\" * 40)\n",
        "\n",
        "for i, class_name in enumerate(CLASSES):\n",
        "    filepath = data_dir / f\"{class_name}.npy\"\n",
        "    \n",
        "    # Charger les données\n",
        "    data = np.load(filepath)\n",
        "    \n",
        "    # Statistiques\n",
        "    data_stats[class_name] = {\n",
        "        'emoji': CLASS_EMOJIS[i],\n",
        "        'count': len(data),\n",
        "        'shape': data.shape,\n",
        "        'size_mb': filepath.stat().st_size / 1024 / 1024,\n",
        "        'min': data.min(),\n",
        "        'max': data.max(),\n",
        "        'mean': data.mean()\n",
        "    }\n",
        "    \n",
        "    stats = data_stats[class_name]\n",
        "    print(f\"{stats['emoji']} {class_name.upper()}\")\n",
        "    print(f\"   📊 Images: {stats['count']:,}\")\n",
        "    print(f\"   📏 Shape: {stats['shape']}\")\n",
        "    print(f\"   💾 Taille: {stats['size_mb']:.1f} MB\")\n",
        "    print(f\"   🎨 Pixels: min={stats['min']}, max={stats['max']}, mean={stats['mean']:.1f}\")\n",
        "    print()\n",
        "\n",
        "# Résumé global\n",
        "total_images = sum(stats['count'] for stats in data_stats.values())\n",
        "total_size = sum(stats['size_mb'] for stats in data_stats.values())\n",
        "\n",
        "print(\"🌟 RÉSUMÉ GLOBAL\")\n",
        "print(\"-\" * 20)\n",
        "print(f\"📊 Total images: {total_images:,}\")\n",
        "print(f\"💾 Total taille: {total_size:.1f} MB\")\n",
        "print(f\"📏 Format images: 28x28 (784 pixels)\")\n",
        "print(f\"🎨 Valeurs pixels: 0-255 (noir=255, blanc=0)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualisation d'exemples de dessins\n",
        "def show_examples(num_examples=5):\n",
        "    \"\"\"Affiche des exemples de dessins pour chaque classe\"\"\"\n",
        "    \n",
        "    fig, axes = plt.subplots(len(CLASSES), num_examples, figsize=(15, 12))\n",
        "    fig.suptitle('🎨 Exemples de dessins Quick Draw', fontsize=16, fontweight='bold')\n",
        "    \n",
        "    for class_idx, class_name in enumerate(CLASSES):\n",
        "        # Charger les données de cette classe\n",
        "        filepath = data_dir / f\"{class_name}.npy\"\n",
        "        data = np.load(filepath)\n",
        "        \n",
        "        # Prendre des exemples aléatoires\n",
        "        random_indices = np.random.choice(len(data), num_examples, replace=False)\n",
        "        \n",
        "        for example_idx in range(num_examples):\n",
        "            ax = axes[class_idx, example_idx]\n",
        "            \n",
        "            # Obtenir l'image et la redimensionner en 28x28\n",
        "            img = data[random_indices[example_idx]].reshape(28, 28)\n",
        "            \n",
        "            # Afficher (inverser les couleurs pour un fond blanc)\n",
        "            ax.imshow(255 - img, cmap='gray')\n",
        "            ax.axis('off')\n",
        "            \n",
        "            # Titre pour la première colonne seulement\n",
        "            if example_idx == 0:\n",
        "                emoji = CLASS_EMOJIS[class_idx]\n",
        "                ax.set_title(f'{emoji} {class_name.title()}', \n",
        "                           fontsize=12, fontweight='bold', pad=10)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "print(\"🖼️ VISUALISATION DES EXEMPLES\")\n",
        "print(\"=\" * 30)\n",
        "show_examples(6)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Distribution des classes et préparation\n",
        "print(\"📊 DISTRIBUTION DES CLASSES\")\n",
        "print(\"=\" * 30)\n",
        "\n",
        "# Graphique de distribution\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
        "\n",
        "# Graphique en barres\n",
        "class_names = list(data_stats.keys())\n",
        "class_counts = [data_stats[name]['count'] for name in class_names]\n",
        "class_labels = [f\"{CLASS_EMOJIS[i]} {name.title()}\" for i, name in enumerate(class_names)]\n",
        "\n",
        "bars = ax1.bar(class_labels, class_counts, color=['#FF6B6B', '#4ECDC4', '#45B7D1', '#96CEB4', '#FFEAA7'])\n",
        "ax1.set_title('Nombre d\\'images par classe', fontsize=14, fontweight='bold')\n",
        "ax1.set_ylabel('Nombre d\\'images')\n",
        "ax1.tick_params(axis='x', rotation=45)\n",
        "\n",
        "# Ajouter les valeurs sur les barres\n",
        "for bar, count in zip(bars, class_counts):\n",
        "    height = bar.get_height()\n",
        "    ax1.text(bar.get_x() + bar.get_width()/2., height + 1000,\n",
        "             f'{count:,}', ha='center', va='bottom', fontweight='bold')\n",
        "\n",
        "# Graphique en camembert\n",
        "ax2.pie(class_counts, labels=class_labels, autopct='%1.1f%%', startangle=90,\n",
        "        colors=['#FF6B6B', '#4ECDC4', '#45B7D1', '#96CEB4', '#FFEAA7'])\n",
        "ax2.set_title('Répartition des classes', fontsize=14, fontweight='bold')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Recommandations pour l'équilibrage\n",
        "print(\"💡 RECOMMANDATIONS POUR L'ENTRAÎNEMENT\")\n",
        "print(\"-\" * 40)\n",
        "\n",
        "min_count = min(class_counts)\n",
        "max_count = max(class_counts)\n",
        "imbalance_ratio = max_count / min_count\n",
        "\n",
        "print(f\"📊 Classe la plus représentée: {max_count:,} images\")\n",
        "print(f\"📉 Classe la moins représentée: {min_count:,} images\") \n",
        "print(f\"⚖️ Ratio de déséquilibre: {imbalance_ratio:.1f}x\")\n",
        "\n",
        "if imbalance_ratio > 1.5:\n",
        "    print(\"⚠️ Déséquilibre détecté ! Options:\")\n",
        "    print(\"   1. Utiliser le même nombre d'images pour toutes les classes\")\n",
        "    print(\"   2. Appliquer des poids aux classes lors de l'entraînement\")\n",
        "    print(\"   3. Augmentation de données pour les classes sous-représentées\")\n",
        "    \n",
        "    # Suggestion d'équilibrage\n",
        "    balanced_count = min_count\n",
        "    print(f\"\\n✅ Suggestion: Utiliser {balanced_count:,} images par classe\")\n",
        "    print(\"   -> Dataset équilibré de\", f\"{balanced_count * len(CLASSES):,} images total\")\n",
        "else:\n",
        "    print(\"✅ Les classes sont bien équilibrées !\")\n",
        "\n",
        "print(\"\\n🚀 PROCHAINES ÉTAPES\")\n",
        "print(\"-\" * 20)\n",
        "print(\"1. Preprocessing: normalisation et redimensionnement\")\n",
        "print(\"2. Split train/validation/test\") \n",
        "print(\"3. Architecture CNN adaptée à 28x28\")\n",
        "print(\"4. Entraînement avec monitoring TensorBoard\")\n",
        "print(\"5. Évaluation et optimisation\")\n",
        "\n",
        "print(\"\\n✨ Données prêtes pour l'entraînement ! ✨\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
